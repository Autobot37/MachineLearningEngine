Traceback (most recent call last):
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py", line 551, in <module>
    t.train()
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py", line 477, in train
    losses = self.estimate_loss(self.config)
  File "C:\Users\SHIVA SINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py", line 518, in estimate_loss
    loss = model.training_step(batch, k)
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py", line 359, in training_step
    logits = self(x)#b t vocab_dim
  File "C:\Users\SHIVA SINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py", line 345, in forward
    t_emb = self.transformer.wte(x)
  File "C:\Users\SHIVA SINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\SHIVA SINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\sparse.py", line 162, in forward
    return F.embedding(
  File "C:\Users\SHIVA SINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\functional.py", line 2210, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mTraceback (most recent call last)[31m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py[39m:[94m551[39m in        [31mâ”‚
[31mâ”‚[39m [92m<module>[39m                                                                                         [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   548                                                                                            [31mâ”‚
[31mâ”‚[39m   549 t = Trainer(config, model, DataModule)                                                     [31mâ”‚
[31mâ”‚[39m   550                                                                                            [31mâ”‚
[31mâ”‚[39m [31mâ± [39m551 t.train()                                                                                  [31mâ”‚
[31mâ”‚[39m   552                                                                                            [31mâ”‚
[31mâ”‚[39m   553                                                                                            [31mâ”‚
[31mâ”‚[39m   554                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py[39m:[94m477[39m in [92mtrain[39m  [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   474 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   475 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   476 â”‚     [94mif[39m iter_num % [96mself[39m.config.eval_interval == [94m0[39m [95mand[39m master_process:                     [31mâ”‚
[31mâ”‚[39m [31mâ± [39m477 â”‚   â”‚   losses = [96mself[39m.estimate_loss([96mself[39m.config)                                           [31mâ”‚
[31mâ”‚[39m   478 â”‚   â”‚   [96mprint[39m([33mf"step {[39miter_num[33m}: eval_loss {[39mlosses[[33m'val'[39m][33m:.4f}"[39m)                           [31mâ”‚
[31mâ”‚[39m   479                                                                                            [31mâ”‚
[31mâ”‚[39m   480                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\utils\_contextlib.py[39m:[94m115[39m   [31mâ”‚
[31mâ”‚[39m in [92mdecorate_context[39m                                                                              [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   112 â”‚   [1m@functools[22m.wraps(func)                                                                 [31mâ”‚
[31mâ”‚[39m   113 â”‚   [94mdef[39m [92mdecorate_context[39m(*args, **kwargs):                                                 [31mâ”‚
[31mâ”‚[39m   114 â”‚   â”‚   [94mwith[39m ctx_factory():                                                                [31mâ”‚
[31mâ”‚[39m [31mâ± [39m115 â”‚   â”‚   â”‚   [94mreturn[39m func(*args, **kwargs)                                                   [31mâ”‚
[31mâ”‚[39m   116 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   117 â”‚   [94mreturn[39m decorate_context                                                                [31mâ”‚
[31mâ”‚[39m   118                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py[39m:[94m518[39m in        [31mâ”‚
[31mâ”‚[39m [92mestimate_loss[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   515 â”‚   [94mfor[39m split [95min[39m [[33m"val"[39m]:                                                                  [31mâ”‚
[31mâ”‚[39m   516 â”‚     losses = torch.zeros(config.eval_iters)                                              [31mâ”‚
[31mâ”‚[39m   517 â”‚     [94mfor[39m k,batch [95min[39m [96menumerate[39m([96mself[39m.dm.val_dataloader()):                                  [31mâ”‚
[31mâ”‚[39m [31mâ± [39m518 â”‚   â”‚   loss = model.training_step(batch, k)                                               [31mâ”‚
[31mâ”‚[39m   519 â”‚   â”‚   losses[k] = loss.item()                                                            [31mâ”‚
[31mâ”‚[39m   520 â”‚   â”‚   [94mif[39m k>config.eval_iters:                                                            [31mâ”‚
[31mâ”‚[39m   521 â”‚   â”‚     [94mbreak[39m                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py[39m:[94m359[39m in        [31mâ”‚
[31mâ”‚[39m [92mtraining_step[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   356 â”‚   x,y = batch                                                                            [31mâ”‚
[31mâ”‚[39m   357 â”‚   x = x.to([96mself[39m.device)                                                                  [31mâ”‚
[31mâ”‚[39m   358 â”‚   y = y.to([96mself[39m.device)                                                                  [31mâ”‚
[31mâ”‚[39m [31mâ± [39m359 â”‚   logits = [96mself[39m(x)#b t vocab_dim                                                         [31mâ”‚
[31mâ”‚[39m   360 â”‚   B,T,vdim = logits.shape                                                                [31mâ”‚
[31mâ”‚[39m   361 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   362 â”‚   logits = logits.view(B*T,vdim)                                                         [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py[39m:[94m1501[39m  [31mâ”‚
[31mâ”‚[39m in [92m_call_impl[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1498 â”‚   â”‚   [94mif[39m [95mnot[39m ([96mself[39m._backward_hooks [95mor[39m [96mself[39m._backward_pre_hooks [95mor[39m [96mself[39m._forward_hooks   [31mâ”‚
[31mâ”‚[39m   1499 â”‚   â”‚   â”‚   â”‚   [95mor[39m _global_backward_pre_hooks [95mor[39m _global_backward_hooks                   [31mâ”‚
[31mâ”‚[39m   1500 â”‚   â”‚   â”‚   â”‚   [95mor[39m _global_forward_hooks [95mor[39m _global_forward_pre_hooks):                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1501 â”‚   â”‚   â”‚   [94mreturn[39m forward_call(*args, **kwargs)                                          [31mâ”‚
[31mâ”‚[39m   1502 â”‚   â”‚   # Do not call functions when jit is used                                          [31mâ”‚
[31mâ”‚[39m   1503 â”‚   â”‚   full_backward_hooks, non_full_backward_hooks = [], []                             [31mâ”‚
[31mâ”‚[39m   1504 â”‚   â”‚   backward_pre_hooks = []                                                           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\Documents\GitHub\MachineLearningEngine\LLM[Deprecated]\lightningMain\main.py[39m:[94m345[39m in        [31mâ”‚
[31mâ”‚[39m [92mforward[39m                                                                                          [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   342   [94mdef[39m [92mforward[39m([96mself[39m,x,y=[94mNone[39m):#X=[B,CONTEXT_SIZE] = B,T                                     [31mâ”‚
[31mâ”‚[39m   343 â”‚   b,t = x.size()                                                                         [31mâ”‚
[31mâ”‚[39m   344 â”‚   pos = torch.arange([94m0[39m,t,dtype=torch.int32, device=[96mself[39m.device).unsqueeze([94m0[39m)             [31mâ”‚
[31mâ”‚[39m [31mâ± [39m345 â”‚   t_emb = [96mself[39m.transformer.wte(x)                                                        [31mâ”‚
[31mâ”‚[39m   346 â”‚   #B,CONTEXT_SIZE,VOCAB_SIZE = B,T,C                                                     [31mâ”‚
[31mâ”‚[39m   347 â”‚   p_emb = [96mself[39m.transformer.wpe(pos)                                                      [31mâ”‚
[31mâ”‚[39m   348 â”‚   x = [96mself[39m.transformer.drop(t_emb+p_emb)                                                 [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py[39m:[94m1501[39m  [31mâ”‚
[31mâ”‚[39m in [92m_call_impl[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1498 â”‚   â”‚   [94mif[39m [95mnot[39m ([96mself[39m._backward_hooks [95mor[39m [96mself[39m._backward_pre_hooks [95mor[39m [96mself[39m._forward_hooks   [31mâ”‚
[31mâ”‚[39m   1499 â”‚   â”‚   â”‚   â”‚   [95mor[39m _global_backward_pre_hooks [95mor[39m _global_backward_hooks                   [31mâ”‚
[31mâ”‚[39m   1500 â”‚   â”‚   â”‚   â”‚   [95mor[39m _global_forward_hooks [95mor[39m _global_forward_pre_hooks):                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1501 â”‚   â”‚   â”‚   [94mreturn[39m forward_call(*args, **kwargs)                                          [31mâ”‚
[31mâ”‚[39m   1502 â”‚   â”‚   # Do not call functions when jit is used                                          [31mâ”‚
[31mâ”‚[39m   1503 â”‚   â”‚   full_backward_hooks, non_full_backward_hooks = [], []                             [31mâ”‚
[31mâ”‚[39m   1504 â”‚   â”‚   backward_pre_hooks = []                                                           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\sparse.py[39m:[94m162[39m   [31mâ”‚
[31mâ”‚[39m in [92mforward[39m                                                                                       [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   159 â”‚   â”‚   â”‚   â”‚   [96mself[39m.weight[[96mself[39m.padding_idx].fill_([94m0[39m)                                     [31mâ”‚
[31mâ”‚[39m   160 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   161 â”‚   [94mdef[39m [92mforward[39m([96mself[39m, [96minput[39m: Tensor) -> Tensor:                                            [31mâ”‚
[31mâ”‚[39m [31mâ± [39m162 â”‚   â”‚   [94mreturn[39m F.embedding(                                                                [31mâ”‚
[31mâ”‚[39m   163 â”‚   â”‚   â”‚   [96minput[39m, [96mself[39m.weight, [96mself[39m.padding_idx, [96mself[39m.max_norm,                           [31mâ”‚
[31mâ”‚[39m   164 â”‚   â”‚   â”‚   [96mself[39m.norm_type, [96mself[39m.scale_grad_by_freq, [96mself[39m.sparse)                          [31mâ”‚
[31mâ”‚[39m   165                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\functional.py[39m:[94m2210[39m in   [31mâ”‚
[31mâ”‚[39m [92membedding[39m                                                                                        [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   2207 â”‚   â”‚   #   torch.embedding_renorm_                                                       [31mâ”‚
[31mâ”‚[39m   2208 â”‚   â”‚   # remove once script supports set_grad_enabled                                    [31mâ”‚
[31mâ”‚[39m   2209 â”‚   â”‚   _no_grad_embedding_renorm_(weight, [96minput[39m, max_norm, norm_type)                    [31mâ”‚
[31mâ”‚[39m [31mâ± [39m2210 â”‚   [94mreturn[39m torch.embedding(weight, [96minput[39m, padding_idx, scale_grad_by_freq, sparse)        [31mâ”‚
[31mâ”‚[39m   2211                                                                                           [31mâ”‚
[31mâ”‚[39m   2212                                                                                           [31mâ”‚
[31mâ”‚[39m   2213 [94mdef[39m [92membedding_bag[39m(                                                                        [31mâ”‚
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[1mRuntimeError: [22mCUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.