Traceback (most recent call last):
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py", line 552, in <module>
    t.train()
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py", line 478, in train
    losses = self.estimate_loss(self.config)
  File "C:\Users\SHIVA SINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py", line 519, in estimate_loss
    loss = model.training_step(batch, k)
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py", line 360, in training_step
    logits = self(x)#b t vocab_dim
  File "C:\Users\SHIVA SINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py", line 345, in forward
    assert isinstance(x)
TypeError: isinstance expected 2 arguments, got 1
[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mTraceback (most recent call last)[31m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
[31mâ”‚[39m [33mC:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py[39m:[94m552[39m in [92m<module>[39m          [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   549                                                                                            [31mâ”‚
[31mâ”‚[39m   550 t = Trainer(config, model, DataModule)                                                     [31mâ”‚
[31mâ”‚[39m   551                                                                                            [31mâ”‚
[31mâ”‚[39m [31mâ± [39m552 t.train()                                                                                  [31mâ”‚
[31mâ”‚[39m   553                                                                                            [31mâ”‚
[31mâ”‚[39m   554                                                                                            [31mâ”‚
[31mâ”‚[39m   555                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py[39m:[94m478[39m in [92mtrain[39m             [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   475 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   476 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   477 â”‚     [94mif[39m iter_num % [96mself[39m.config.eval_interval == [94m0[39m [95mand[39m master_process:                     [31mâ”‚
[31mâ”‚[39m [31mâ± [39m478 â”‚   â”‚   losses = [96mself[39m.estimate_loss([96mself[39m.config)                                           [31mâ”‚
[31mâ”‚[39m   479 â”‚   â”‚   [96mprint[39m([33mf"step {[39miter_num[33m}: eval_loss {[39mlosses[[33m'val'[39m][33m:.4f}"[39m)                           [31mâ”‚
[31mâ”‚[39m   480                                                                                            [31mâ”‚
[31mâ”‚[39m   481                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\utils\_contextlib.py[39m:[94m115[39m   [31mâ”‚
[31mâ”‚[39m in [92mdecorate_context[39m                                                                              [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   112 â”‚   [1m@functools[22m.wraps(func)                                                                 [31mâ”‚
[31mâ”‚[39m   113 â”‚   [94mdef[39m [92mdecorate_context[39m(*args, **kwargs):                                                 [31mâ”‚
[31mâ”‚[39m   114 â”‚   â”‚   [94mwith[39m ctx_factory():                                                                [31mâ”‚
[31mâ”‚[39m [31mâ± [39m115 â”‚   â”‚   â”‚   [94mreturn[39m func(*args, **kwargs)                                                   [31mâ”‚
[31mâ”‚[39m   116 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   117 â”‚   [94mreturn[39m decorate_context                                                                [31mâ”‚
[31mâ”‚[39m   118                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py[39m:[94m519[39m in [92mestimate_loss[39m     [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   516 â”‚   [94mfor[39m split [95min[39m [[33m"val"[39m]:                                                                  [31mâ”‚
[31mâ”‚[39m   517 â”‚     losses = torch.zeros(config.eval_iters)                                              [31mâ”‚
[31mâ”‚[39m   518 â”‚     [94mfor[39m k,batch [95min[39m [96menumerate[39m([96mself[39m.dm.val_dataloader()):                                  [31mâ”‚
[31mâ”‚[39m [31mâ± [39m519 â”‚   â”‚   loss = model.training_step(batch, k)                                               [31mâ”‚
[31mâ”‚[39m   520 â”‚   â”‚   losses[k] = loss.item()                                                            [31mâ”‚
[31mâ”‚[39m   521 â”‚   â”‚   [94mif[39m k>config.eval_iters:                                                            [31mâ”‚
[31mâ”‚[39m   522 â”‚   â”‚     [94mbreak[39m                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py[39m:[94m360[39m in [92mtraining_step[39m     [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   357 â”‚   x,y = batch                                                                            [31mâ”‚
[31mâ”‚[39m   358 â”‚   x = x.to([96mself[39m.device)                                                                  [31mâ”‚
[31mâ”‚[39m   359 â”‚   y = y.to([96mself[39m.device)                                                                  [31mâ”‚
[31mâ”‚[39m [31mâ± [39m360 â”‚   logits = [96mself[39m(x)#b t vocab_dim                                                         [31mâ”‚
[31mâ”‚[39m   361 â”‚   B,T,vdim = logits.shape                                                                [31mâ”‚
[31mâ”‚[39m   362 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   363 â”‚   logits = logits.view(B*T,vdim)                                                         [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA [39m                                                                                  [31mâ”‚
[31mâ”‚[39m [33mSINGH\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py[39m:[94m1501[39m  [31mâ”‚
[31mâ”‚[39m in [92m_call_impl[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1498 â”‚   â”‚   [94mif[39m [95mnot[39m ([96mself[39m._backward_hooks [95mor[39m [96mself[39m._backward_pre_hooks [95mor[39m [96mself[39m._forward_hooks   [31mâ”‚
[31mâ”‚[39m   1499 â”‚   â”‚   â”‚   â”‚   [95mor[39m _global_backward_pre_hooks [95mor[39m _global_backward_hooks                   [31mâ”‚
[31mâ”‚[39m   1500 â”‚   â”‚   â”‚   â”‚   [95mor[39m _global_forward_hooks [95mor[39m _global_forward_pre_hooks):                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1501 â”‚   â”‚   â”‚   [94mreturn[39m forward_call(*args, **kwargs)                                          [31mâ”‚
[31mâ”‚[39m   1502 â”‚   â”‚   # Do not call functions when jit is used                                          [31mâ”‚
[31mâ”‚[39m   1503 â”‚   â”‚   full_backward_hooks, non_full_backward_hooks = [], []                             [31mâ”‚
[31mâ”‚[39m   1504 â”‚   â”‚   backward_pre_hooks = []                                                           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m [33mC:\Users\SHIVA SINGH\Documents\GitHub\MachineLearningEngine\LLM\main.py[39m:[94m345[39m in [92mforward[39m           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   342   [94mdef[39m [92mforward[39m([96mself[39m,x,y=[94mNone[39m):#X=[B,CONTEXT_SIZE] = B,T                                     [31mâ”‚
[31mâ”‚[39m   343 â”‚   b,t = x.size()                                                                         [31mâ”‚
[31mâ”‚[39m   344 â”‚   pos = torch.arange([94m0[39m,t,dtype=torch.int32, device=[96mself[39m.device).unsqueeze([94m0[39m)             [31mâ”‚
[31mâ”‚[39m [31mâ± [39m345 â”‚   [94massert[39m [96misinstance[39m(x)                                                                   [31mâ”‚
[31mâ”‚[39m   346 â”‚   t_emb = [96mself[39m.transformer.wte(x)                                                        [31mâ”‚
[31mâ”‚[39m   347 â”‚   #B,CONTEXT_SIZE,VOCAB_SIZE = B,T,C                                                     [31mâ”‚
[31mâ”‚[39m   348 â”‚   p_emb = [96mself[39m.transformer.wpe(pos)                                                      [31mâ”‚
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[1mTypeError: [22misinstance expected [1m2[22m arguments, got [1m1